{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from xarray import DataArray\n",
    "import pandas as pd\n",
    "# from PyEMD import EEMD\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "na = np.load(\"/work/uo1075/u241321/data/eemd_NAO_DJF_dt.npy\") # grid point detrend\n",
    "spg = np.load(\"/work/uo1075/u241321/data/EEMD_spg_density_raw_c14.npy\")  #\n",
    "tend = np.load(\"/work/uo1075/u241321/data/eemd_tend_Norwegian.npy\")\n",
    "temp = np.load(\"/work/uo1075/u241321/data/eemd_t310_Norwegian.npy\")\n",
    "slheat = np.load(\"/work/uo1075/u241321/data/eemd_slheat_Norwegian.npy\")\n",
    "# transport = np.load(\"/work/uo1075/u241321/data/eemd_htransport310.npy\") \n",
    "# transport1 = np.load(\"/work/uo1075/u241321/data/eemd_htransport310_ifc.npy\") \n",
    "s_transport = np.load(\"/work/uo1075/u241321/data/stransport310_IFC_FSC.npy\") \n",
    "slheat_djf = np.load(\"/work/uo1075/u241321/data/eemd_slheat_DJF_Norwegian.npy\")\n",
    "# nao = np.load(\"/work/uo1075/u241321/data/NAO_DJF_assi.npy\")\n",
    "# nao = np.load(\"/work/uo1075/u241321/data/eemd_NAO_DJF.npy\")   #  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.40514461],\n",
       "       [0.40514461, 1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nao=na[2,:]+na[3,:]+na[4,:]\n",
    "\n",
    "trans_fsc = np.load(\"/work/uo1075/u241321/data/eemd_htransport310.npy\")\n",
    "trans_ifc = np.load(\"/work/uo1075/u241321/data/eemd_htransport310_ifc.npy\")\n",
    "\n",
    "transport = trans_fsc[2,:] + trans_ifc[2,:]+ trans_fsc[3,:] + trans_ifc[3,:]+ trans_fsc[4,:] + trans_ifc[4,:] \n",
    "\n",
    "np.corrcoef(nao,transport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spg1 = np.load(\"/work/uo1075/u241321/data/EEMD_spg_density.npy\")   # (5,50) mode(input, c1-c4), time\n",
    "spg = spg1[2,:]+spg1[3,:]+spg1[4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "na = np.load(\"/work/uo1075/u241321/data/eemd_NAO_DJF.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.45225539],\n",
       "       [0.45225539, 1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(na[0,:], trans_fsc[0,:]+ trans_ifc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.53940842],\n",
       "       [0.53940842, 1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(na[0,:], s_transport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.38210369],\n",
       "       [0.38210369, 1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(transport[0,:]+ transport1[0,:], temp[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.34798698],\n",
       "       [0.34798698, 1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(transport[0,:]+ transport1[0,:], temp[1,:]+temp[2,:]+temp[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.24305276],\n",
       "       [0.24305276, 1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(transport[0,:], temp[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.13115228],\n",
       "       [0.13115228, 1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(transport[1,:], temp[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 49)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slheat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Original script; with trend # result is almost same as the result of fft function\n",
    "def rho(datax):\n",
    "    # Calculates the lag-1 Autocorrelation Coefficient.\n",
    "    import numpy as np  \n",
    "    nrho=len(datax)\n",
    "    sommesup=0\n",
    "    sommeinf=0\n",
    "    moy=np.sum(datax)/nrho\n",
    "    datam=datax-moy\n",
    "    for i in np.arange(1,nrho):\n",
    "        j=i-1\n",
    "        sommesup=sommesup+(datam[i]*datam[j])\n",
    "        sommeinf=sommeinf+(datam[j]**2)\n",
    "    rho=sommesup/sommeinf\n",
    "    return rho\n",
    "\n",
    "def rhoAlt(datax,dt=1):\n",
    "    # Calculates the lag-dt Autocorrelation Coefficient, given the dt.\n",
    "    import numpy as np  \n",
    "    r=np.corrcoef(datax[0:-dt-1],datax[dt:-1])\n",
    "    return r[0,1]\n",
    "\n",
    "def rednoise(lenx, rho, nsim=1000, dist='normal', returnWhite=False, \n",
    "             mean=0, std=1, lo=-1, hi=1):\n",
    "    '''\n",
    "    Creates nsim time series of rednoise of length=lenx, with lag-1 autocorrelation rho.\n",
    "    For normally-distributed series, user can provide mean and std.\n",
    "    For uniformely-distributed series, user can provide low and high bounds.\n",
    "    '''\n",
    "    import numpy as np\n",
    "    srho=(1-(rho**2))**(0.5)\n",
    "    red=np.zeros((lenx,nsim))\n",
    "    white=np.zeros((lenx,nsim))\n",
    "    for j in range(nsim):\n",
    "        for i in range(lenx):\n",
    "            if dist=='normal':\n",
    "                white[i,j]=np.random.normal(loc=mean, scale=std) \n",
    "            elif dist=='uniform':\n",
    "                white[i,j]=np.random.uniform(low=lo, high=hi)\n",
    "    for j in range(nsim):\n",
    "        for i in range(lenx):\n",
    "            if i==0:\n",
    "                red[i,j]=white[i,j]*srho\n",
    "            else:\n",
    "                red[i,j]=rho*red[i-1,j]+white[i,j]*srho\n",
    "    if returnWhite:\n",
    "        return red, white\n",
    "    else:\n",
    "        return red\n",
    "    \n",
    "def periods(x,dt,returnPeriods=True, nsim=1000):\n",
    "    import numpy as np\n",
    "    from scipy import signal\n",
    "    from scipy.stats.distributions import chi2\n",
    "    \n",
    "    # Calculate periodogram of x\n",
    "    f, psd = signal.periodogram(x,fs=dt,detrend=False,scaling='spectrum')\n",
    "    per=1/f\n",
    "    max5=np.zeros((5,3))\n",
    "    psdc=psd.copy()\n",
    "\n",
    "    # Get the 5 larges periods\n",
    "    for i in range(5):\n",
    "        max5[i,0]=f[psdc==max(psdc)]\n",
    "        max5[i,1]=psdc[psdc==max(psdc)]\n",
    "        max5[i,2]=per[psdc==max(psdc)]\n",
    "        psdc[psdc==max(psdc)]=0\n",
    "\n",
    "    # Calculate periodograms of the nsim red-noise series\n",
    "    fn=np.zeros((len(f),nsim))\n",
    "    Pn=np.zeros((len(f),nsim))\n",
    "    red=rednoise(len(x),rhoAlt(x,dt=dt),dist='normal',nsim=nsim)\n",
    "    for i in range(nsim):\n",
    "    #         if np.remainder(i,100)==0:\n",
    "    #             print('%.0f %%' %(i/10))\n",
    "        fn[:,i], Pn[:,i] = signal.periodogram(red[:,i],fs=dt,detrend=False,scaling='spectrum')\n",
    "\n",
    "    # Mean spectrum of nsim simulations\n",
    "    meanRed=np.mean(Pn,axis=1)\n",
    "\n",
    "    # Get Percentiles of Distribution of Red-Noise Spectra\n",
    "    pctl=np.zeros((len(f),4)) # 0.8, 0.9, 0.95, 0.99\n",
    "    for i in range(len(f)):\n",
    "        pctl[i,0]=np.percentile(Pn[i,:],80)\n",
    "        pctl[i,1]=np.percentile(Pn[i,:],90)\n",
    "        pctl[i,2]=np.percentile(Pn[i,:],95)\n",
    "        pctl[i,3]=np.percentile(Pn[i,:],99)\n",
    "     \n",
    "   \n",
    "    frequency = f\n",
    "    spectrum = psd\n",
    "    return frequency, spectrum, pctl, max5, meanRed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_799235/3280903895.py:58: RuntimeWarning: divide by zero encountered in divide\n",
      "  per=1/f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fre, spe, pct1, max5, meanred = periods(na[3,:],1,returnPeriods=True, nsim=1000)\n",
    "max5[0,2]  # largest period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1 Python 3 (based on the module python3/2023.01)",
   "language": "python",
   "name": "python3_2023_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
